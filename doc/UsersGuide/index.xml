<?xml version='1.0'?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
"http://www.oasis-open.org/docbook/xml/4.1.2/docbookx.dtd" [
]>

<book label="CLM4_UsersGuide" status="draft">

<bookinfo>
<title>CCSM Research Tools: CLM4.0 Users Guide Documentation (DRAFT)</title>

<authorgroup>

<author>
    <firstname>Erik</firstname>
    <surname>Kluzek</surname>
   <affiliation>
   <orgname> NCAR </orgname>
   </affiliation>
</author>

</authorgroup>

<date>2010-04-01</date>
                     
</bookinfo>

<dedication>
<para>
Dedicated to the Land Model Working Group winners of the 2008 CCSM Distinguished Achievement Award.
</para>
</dedication>

<preface id="acknowledge">
<title>Acknowledgments</title>
<para>
We acknowledge all of the people that helped review or edit the model documentation: 
David Lawrence, Samuel Levis, and Keith Oleson. 
</para>
</preface>

<preface id="intro">
<title>Introduction</title>

<para>
The Community Land Model (CLM) is the latest in a series of
global land models developed at the National Center for
Atmospheric Research (NCAR). This guide is intended to instruct both
the novice and experienced user on running CLM.
</para>
</preface>

<!-- ======================================================================= -->
<preface id="how_to">
<title>How to Use This Document</title>

<para>
This section provides the details in using CLM with the CCSM modeling
system. Links to descriptions and definitions have been provided in the code below.
We use the same conventions used in the CCSM documentation as outlined below.
</para>

<screen>
Throughout the document this style is used to indicate shell
commands and options, fragments of code, namelist variables, etc.
Where examples from an interactive shell session are presented, lines
starting with > indicate the shell prompt. Note that "$EDITOR" is used
to refer to the text editor of your choice. $EDITOR is a standard UNIX
environment variable and should be set on most UNIX systems. Comment
lines are signaled to start with a "#" sign, which is the standard UNIX
comment sign as well.
</screen>

</preface>


<!-- ======================================================================= -->
<preface id="what_is_new">
<title>What is new with CLM4 since CLM3.5?</title>

<para>
Since CLM3.5 there have been advances in both the science and the software infrastructure.
</para>

<sect1 id="science">
<title>What is new with CLM4 Science?</title>
<para>
The following aspects are changes to the science in CLM since CLM3.5.
</para>
<para>
Changes to CLM4 beyond CLM3.5 (Oleson et al., 2008a; Stockli et al., 2008) include updates throughout the model. The hydrology scheme has been modified with a revised numerical solution of the Richards equation (Zeng and Decker, 2009; Decker and Zeng, 2009); a revised soil evaporation parameterization that removes the soil resistance term introduced in CLM3.5 and replaces it with a so-called	formulation, as well as accounts for the role of litter and within-
canopy stability (Sakaguchi and Zeng, 2009).
</para>
<para>
The snow model is significantly modified via incorporation of SNICAR (SNow and Ice Aerosol Radiation) which represents the effect of aerosol deposition (e.g. black and organic carbon and dust) on albedo, introduces a grain-size dependent snow aging parameterization, and permits vertically resolved snowpack heating (Flanner and Zender, 2005; Flanner and Zender, 2006; Flanner et al., 2007). The new snow model also includes a new density-dependent snow cover fraction parameterization (Niu and Yang, 2007), a revised snow burial fraction over short vegetation (Wang and Zeng, 2009) and corrections to snow compaction (Lawrence and Slater, 2009).
</para>
<para>
CLM4 also includes a representation of the thermal and hydraulic properties of organic soil that operates in conjunction with the mineral soil properties (Lawrence and Slater, 2008). The ground column has been extended to ~50-m depth by adding five additional hydrologically inactive ground layers (making a total of 15 ground layers, 10 soil layers and 5 bedrock layers; Lawrence et al., 2008). An urban landunit and associated urban canyon model has been added which permits the study of urban climate and urban heat island effects (Oleson et al., 2008b). The PFT distribution is as in Lawrence and Chase (2007) except that a new cropping dataset is used (Ramankutty et al., 2008) and a grass PFT restriction has been put in place to reduce a high grass PFT bias in forested regions by replacing the herbaceous fraction with low trees rather than grass. Grass and crop PFT optical properties have been adjusted according to values presented in Asner et al. (1998), resulting in significantly reduced albedo biases. Soil colors have been re-derived according to the new PFT distribution.
</para>
<para>
The model is extended with a carbon-nitrogen biogeochemical model (Thornton et al., 2007; Thornton et al., 2009; Randerson et al., 2009) which is referred to as CLM4CN. CN is based on the terrestrial biogeochemistry Biome-BGC model with prognostic carbon and nitrogen cycle (Thornton et al., 2002; Thornton and Rosenbloom, 2005). CLM4CN is prognostic with respect to carbon and nitrogen state variables in the vegetation, litter, and soil organic matter. Vegetation phenology and canopy heights are also prognostic. A detailed description of the biogeochemical component can be found in Thornton et al. (2007). Note that CLM4 can be run with either prescribed satellite phenology (CLM4SP) or with prognostic phenology provided by the carbon- nitrogen cycle model (CLM4CN). Additionally, a transient land cover and land use change, including wood harvest, capability has been introduced that enables the evaluation of the impact of historic and future land cover and land use change on energy, water, and momentum fluxes as well as carbon and nitrogen fluxes.	The dynamic global vegetation model in CLM3 has been revised such that the carbon dynamics (e.g. productivity, decomposition, phenology, allocation, etc.) are controlled by CN and only the dynamic vegetation biogeography (competition) aspect of the CLM3 DGVM is retained.
</para>
<para>
Several other minor changes have been incorporated including a change to the atmospheric reference height so that it is the height above zo+d for all surface types. The convergence of
canopy roughness length zo and displacement height d to bare soil values as the above-ground biomass, or the sum of leaf and stem area indices, goes to zero is ensured (Zeng and Wang, 2007). Several corrections have been made to the way the offline forcing data is interpreted. The main change is a vastly improved and smooth diurnal cycle of incoming solar radiation that conserves the total incoming solar radiation from the forcing dataset. Additionally, in offline mode rather than partitioning incoming solar radiation into a constant 70%/30% direct vs diffuse split, it is partitioned according to empirical equations that are a function of total solar radiation. Finally, to improve global energy conservation in fully coupled simulations, runoff is split into separate liquid and ice water streams that are passed separately to the ocean. Input to the ice water comes from excess snowfall in snow-capped regions. The biogenic volatile organic compounds model (BVOC) that was available in CLM3 has been replaced with the MEGAN BVOC model (Heald et al. 2008).
</para>
<para>
Taken together, these augmentations to CLM3.5 result in improved soil moisture dynamics that lead to higher soil moisture variability and drier soils. Excessively wet and unvarying soil moisture was recognized as a deficiency in CLM3.5 (Oleson et al. 2008a, Decker and Zeng, 2009). The revised model also simulates, on average, higher snow cover, cooler soil temperatures in organic-rich soils, greater global river discharge, lower albedos over forests and grasslands, and higher transition-season albedos in snow covered regions, all of which are improvements compared to CLM3.5.
</para>
</sect1>
<sect1 id="software">
<title>What is new with CLM4 Software Infrastructure?</title>
<para>
The following aspects are changes to the software infrastructure in CLM since CLM3.5.
</para>
<para>
<simplelist>
    <member>Update to cpl7 and scripts.</member>
    <member>Remove offline and cpl6 modes.</member>
    <member>Remove support for CASA model.</member>
    <member>Update to datm8 atmospheric data model.</member>
    <member>Add gx3v7 land mask for T31 and fv-4x5 horizontal resolutions.</member>
    <member>Add gx1v6 land mask for f05, f09, and f19 horizontal resolutions.</member>
    <member>Add tx1v1 land mask and 1.9x2.5_tx1v1 horizontal resolution.</member>
    <member>Add in 2.5x3.33 horizontal resolution.</member>
    <member>Add in T62 horizontal resolution so can run at same resolution as input datm
data.</member>
    <member>Allow first history tape to be 1D.</member>
    <member>Add ability to use own version of input datasets with CLM_USRDAT_NAME
variable.</member>
    <member>Add a script to extract out regional datasets.</member>
    <member>New build-namelist system with XML file describing all namelist
items.</member>
    <member>Add glacier_mec use-case and stub glacier model.</member>
    <member>Add ncl script to time-interpolate between 1850 and 2000 for fndepdat
dataset, for fndepdyn version.</member>
    <member>Make default of maxpatch_pft=numpft+1 instead of 4.</member>
    <member>Only output static 3D fields on first h0 history file to save space.</member>
    <member>Add new fields for VOC (Volatile Organic Compounds) on some surface datasets, that will be 
    needed for the new MEGAN VOC model (NOT incorporated yet).</member>
    <member>Add irrigation area to mksurfdata tool (NOT used in CLM yet).</member>
    <member>Add multiple elevation class option for glaciers in mksurfdata tool (NOT used
in CLM yet).</member>
    <member>Add ascale field to land model in support of model running on it's own
grid.</member>
</simplelist>
</para>
</sect1>

</preface>

<!-- ======================================================================= -->
<preface id="quickstart">
<title>Quickstart to using CLM4</title>
<para>
Before working with CLM4 read the QuickStart Guide in the
<ulink url="http://www.ccsm.ucar.edu/models/ccsm4.0/ccsm_doc/book1.html">CCSM4.0
Scripts User Guide</ulink>. Once you are familiar with how to setup cases for 
any type of simulation with CCSM you will want to direct your attention to the specifics
of using CLM.
</para>
<para>
For some of the details of setting up cases for CLM4 read the README and text files available
from the "models/lnd/clm/doc" directory (see the "CLM Web pages" section for a link to the list
of these files). Here are the important ones that you should be familiar with.
<orderedlist>
<listitem><para><ulink url="../README">README</ulink> file describing the directory structure.</para></listitem>
<listitem><para><ulink url="../Quickstart.userdatasets">Quickstart.userdatasets</ulink> file describing how to
use your own datasets in the model.</para></listitem>
<listitem><para><ulink url="../KnownBugs">KnownBugs</ulink> file describing known problems in CLM4.</para></listitem>
</orderedlist>
</para>
<para>The <emphasis>IMPORTANT_NOTES</emphasis> file is given in the next chapter on what is functional/validated in CLM4?
</para>
<para>The <emphasis>ChangeLog/ChangeSum</emphasis> files are largely explained in the previous chapter on "What is new with
CLM4?"</para>
<para>
Note other directories have README files that explain different components and tools used when running CLM and are useful in
understanding how those parts of the model work and should be consulted when using tools in those directories.
</para>
<para>The <emphasis>Quickstart.GUIDE</emphasis> is repeated in the section below.</para>
<programlisting>
Assumptions: You want to use bluefire with clm4
             to do a clm simulation with data atmosphere and the
             latest atm forcing files and settings. You also want to cycle
             the atm data between 1948 to 2004 and you want to run at
             1.9x2.5 degree resolution.

Process:

   # Create the case

   cd scripts

   ./create_newcase -case testcase -mach bluevista -res f19_g15 -compset I4804 -skip_rundb
   (./create_newcase -help -- to get help on the script)
TRUE

   # Configure the case

   cd testcase
   $EDITOR env_run.xml env_conf.xml   # If you need to make changes (or use the xmlchange script)
   ./configure -case
   (./configure -help -- to get help on the script)

   # Make any changes to the namelist

   $EDITOR Buildconf/clm.buildnml_prestage.csh

   # Compile the code

   ./testcase.build

   # Submit the run

   bsub < testcase.run

Information on Compsets:

     "I" compsets are the ones with clm and datm7 without ice and ocean.
     The latest "I" compsets use the new CLM_QIAN data with solar following
     the cosine of solar zenith angle, precipitation constant, and other
     variables linear interpolated in time (and with appropriate time-stamps on
     the date).

     Name                 (short-name): Description
     --------------------------------------------------------------------------
     I_2000           (I):         CLM to simulate year=2000
     I_1850           (I1850):     CLM to simulate year=1850
     I_1948_2004      (I4804):     CLM running with atm data over 1948-2004
     I_1850-2000      (I8520):     CLM with transient PFT over 1850-2000
     I_2000_CN        (ICN):       CLM with CN on to simulate year=2000
     I_1850_CN        (I1850CN):   CLM with CN on to simulate year=1850
     I_1948-2004_CN   (I4804CN):   CLM with CN on running with atm data over 1948-2004
     I_1850-2000_CN   (I8520CN):   CLM with CN on with transient PFT over 1850-2000

Information on run-database:

    -skip_rundb says to skip entering information on this case into the run-database.
    The run-database stores meta-data on simulations being performed so they can
    be shared effectively with collaborators. The information on how to redo a simulation
    as well as where the simulation is stored and any diagnostics on it are stored in
    the run data-base. The run data-base is on the web at...

    http://ccsm-rundb.cgd.ucar.edu/case_list.php

    It contains information on important cases that we want to retain information on
    (so they can be reproduced and so scientific details are publicly available).
    The standard CSM internal user-name/password is used for the database (as for the CSEG
    internal web-page).

Automatically resubmitting jobs:

   After doing a short simulation that you believe is correct

   $EDITOR env_run.xml

   # Change RESUBMIT to number greater than 0, and CONTINUE_RUN to TRUE...

   bsub < testcase.run
</programlisting>
</preface>
<!-- ======================================================================= -->
<preface id="whats_validated">
<title>What is scientifically validated and functional in CLM4?</title>

<sect1 id="config_not_validated">
<title>Configure Modes NOT scientifically validated, documented, supported or even advised to be used:</title>
<para>
<orderedlist>
<listitem>
   <para>
   <varname>C13</varname><screen>(-c13)</screen>
       The C13 mode for bgc=cn is NOT scientifically validated or documented and NOT recommended to be used.
   </para>

</listitem>
<listitem>
   <para>
   <varname>CASA</varname><screen>(-bgc casa)</screen>
       The bgc=casa mode is NOT scientifically validated or documented and NOT recommended to be used.
   </para>

</listitem>
<listitem>
   <para>
   <varname>DGVM</varname><screen>(-bgc dgvm)</screen>
       The bgc=dgvm  mode is NOT scientifically validated or documented and NOT recommended to be used.
       This mode will be replaced by CNDV (coupled with bgc=cn mode) in the final CLM4.0 release (see below).
   </para>
</listitem>
<listitem>
   <para>
   <varname>BUILDPIO</varname><screen>(-pio)</screen>
       This mode is NOT tested and not even functional and hence should NOT be used. PIO WILL be provided
       in future versions however.
   </para>
</listitem>
<listitem>
   <para>
   <varname>SNICAR_FRC</varname><screen>(-snicar_frc)</screen>
       This mode is tested and functional, but is NOT constantly scientifically validated, and should be 
       considered experimental.
   </para>
</listitem>
<listitem>
   <para>
   <varname>PERGRO</varname><screen>(-pergro)</screen>
       This mode is tested to be functional, but NOT scientifically validated. It's purpose is in an attempt
       to validate that a port to a new machine is reasonable, or changes that are only roundoff will NOT 
       affect the climate. The best method for this validation is to run 100 year simulations with both and
       make sure the climate is similar between each. We hope to validate the method using PERGRO in future
       versions of the model.
   </para>
</listitem>
</orderedlist>
</para>
</sect1>

<sect1 id="changes_expected">
<title>Changes expected to happen for the official CCSM4.0 release:</title>
<para>
<orderedlist>
<listitem><para><emphasis><varname>CNDV</varname> mode will be available: (replaces the DGVM mode)</emphasis>
       A Dynamic Vegetation mode coupled to the Carbon Nitrogen (bgc=cn) biogeochemistry mode WILL be provided
       in the main CLM4.0 release.</para>
</listitem>

<listitem><para><emphasis><varname>VOC</varname> version will be updated:</emphasis>
       The current Volatile Organic Compounds option used in CLM is the older version and NOT the newer MEGAN
       version. The new MEGAN version WILL be provided in the main CLM4.0 release.</para>
</listitem>
</orderedlist>
</para>
</sect1>

<sect1 id="nml_not_validated">
<title>Namelist items that should NOT be exercised:</title>
<para>
<orderedlist>
<listitem><para><emphasis>create_crop_landunit:</emphasis>  Functional, but experimental</para>
</listitem>
<listitem><para><emphasis>urban_traffic:</emphasis>         Not currently functional</para>
</listitem>
<listitem><para><emphasis>pio namelist options:</emphasis>  hist_pioflag, ncd_lowmem2d, ncd_pio_def, ncd_pio_UseRearranger, ncd_pio_UseBoxRearr, 
                         ncd_pio_SerialCDF, ncd_pio_DebugLevel, and ncd_pio_num_iotasks
        These options are NOT currently tested or functional. See the pio configure mode above.</para>
</listitem>
<listitem><para><emphasis>casa namelist options:</emphasis> lnpp, lalloc, q10, spunup, and fcpool

        As above CASA is NOT scientifically validated and hence we don't recommend using it, thus we don't
        recommend using the casa namelist options (they are only available when running with CASA).</para>
</listitem>
</orderedlist>
</para>
</sect1>
</preface>

<!-- ======================================================================= -->
<preface id="help">
<title>Other resources to get help from</title>

<sect1 id="CCSM_UG">
<title>The CCSM Users-Guide</title>
<para>
CLM4 is always run from within the standard CCSM4 build and run scripts. Therefore, the user of CLM4
should familiarize themselves with the CCSM4 scripts and understand and know how to work with them.
Users-Guide documentation on the CCSM4 scripts are available from the following web-page. The purpose
of this CLM4 Users Guide is to give the CLM4 user better descriptions and more details on how to work
with CLM and the set of tools that support CLM, as well as give examples that are unique to the use
of CLM. But, the CCSM4 Scripts Users-Guide is the source to get detailed understanding of how to build
and run the CCSM system in total.
<simplelist>
<member><ulink url="http://www.ccsm.ucar.edu/models/ccsm4.0/ccsm_doc/book1.html">CCSM4.0 Scripts
Users-Guide</ulink></member>
</simplelist>
</para>
</sect1>

<sect1 id="CCSM_BB">
<title>The CCSM Bulletin Board</title>
<para>
There is a rich and diverse set of people that use the CCSM, and often it is useful to be in contact with
others to get help in solving problems or trying something new. To facilitate this we have an online
Bulletin Board for questions on the CCSM. There are also different sections in the Bulletin Board for
the different component models or for different topics.
<simplelist>
<member><ulink url="http://bb.cgd.ucar.edu/">CCSM Online Bulletin Board</ulink></member>
</simplelist>
</para>
</sect1>

<sect1 id="CLM_web">
<title>The CLM web pages</title>
<para>
The main CLM web page contains information on the CLM, it's history, developers, as well as
downloads for previous model versions. There are also documentation text files in the 
models/lnd/clm/doc directory that give some quick information on using CLM.
<simplelist>
<member><ulink url="http://www.cgd.ucar.edu/tss/clm/">CLM web page</ulink></member>
<member><ulink url="../">CLM Documentation Text Files</ulink></member>
</simplelist>
</para>
</sect1>

<sect1 id="reporting_bugs">
<title>Reporting bugs in CLM4</title>
<para>
If you have any problems, additional questions, bug reports, or any other feedback, please send an email to
ccsm4-help@cgd.ucar.edu.
</para>
</sect1>

</preface>

<!-- End introduction preface -->

<!-- ======================================================================= -->
<!-- Beg of customizing section -->

<chapter id="customize">
<title>How to customize the configuration for a case with CLM</title>

<para>
The <ulink url="http://www.ccsm.ucar.edu/models/ccsm4.0/ccsm_doc/book1.html">
CCSM Users Guide</ulink> gives you the details on how to setup, configure, build, and run
a case. That is the document to give you the details on using the CCSM scripts. The purpose 
of this document is to give you the details when using CCSM with CLM on how to customize
and use advanced features in CLM. You should be familiar with the CCSM Users Guide and
how to setup cases with CCSM4 before referring to this document.
</para>
<para>
In this chapter we deal with three different ways of customizing a case: Choosing a compset,
Customizing Configuration options, and customizing the CLM Namelist. There are many different
compsets that use CLM and many are setup to enable special features of CLM from the start. So
the first thing you want to be familiar with are the different options in the compsets. The 
next section shows the different options for customizing the configuration options for CLM.
Here we introduce the CLM configure and build-namelist scripts and how using the
<filename>env_conf.xml</filename> options you can customize the configuration and the initial
namelist. The final section tells you about the CLM namelist and how you could customize the
namelist once you have run "configure -case" and have an initial namelist in
<filename>BuildConf/clm.buildnml.csh</filename> that you can customize by hand. You can also 
use <filename>env_conf.xml</filename> options to change you namelist as well.
</para>
<!-- Beg of choosing a compset section -->
<sect1 id="compset_choice">
<title>Choosing a compset using CLM</title>

<para>
When setting up a new case one of the first choices to make is which "component set" (or compset) to use. The
compset refers to which component models are used as well as specific settings for them. We label the different
types of compsets with a different letter of the alphabet from "A" (for all data model) to "X" (for all dead model).
The compsets of interest when working with CLM are the "I" compsets (which contain CLM with a data atmosphere model
and a stub ocean, and stub sea-ice models), "E" and "F" compsets (which contain CLM with the active atmosphere model (CAM),
a prescribed sea-ice model and a data ocean model), and "B" compsets which have all active components. Below we
go into details on the "I" compsets which emphasize CLM as the only active model, and just mention the two other categories.
</para>
<para>
When working with CLM you usually want to start with a relevant "I" compset before moving to the more
complex cases that involve other active model components. The "I" compsets can exercise CLM in a way that
is similar to the coupled modes, but with much lower computational cost and faster turnaround times.
</para>
<sect2 id="I_compsets">
<title>Compsets coupled to data atmosphere and stub ocean/sea-ice ("I" compsets)</title>
<orderedlist>
       <listitem><para><varname>I_2000</varname> for vegetation types simulating year 2000 AD.</para></listitem>
       <listitem><para><varname>I_1850</varname> for vegetation types simulating year 1850 AD.</para></listitem>
<!--
       <listitem><para><varname>I_GLC</varname> for running with the glacier model (2000 AD conditions).</para></listitem>
-->
       <listitem><para><varname>I_1948_2004</varname> for 2000 AD simulation year running over atmospheric
           data from 1948 to 2004.</para></listitem>
       <listitem><para><varname>I_1850-2000</varname> for 20th Century simulations varying the vegetation
          types from 1850 to 2000 AD.</para></listitem>
       <listitem><para><varname>I_CN</varname> for 2000 AD simulation year running with CN BGC model.</para></listitem>
       <listitem><para><varname>I_1850_CN</varname> for 1850 AD simulation year running with CN BGC model.</para></listitem>
<!--
       <listitem><para><varname>I_1850_SPINUP_3HrWxHfHrSol_CN</varname> for 1850 AD simulation year running
          with CN BGC model and using 3-hourly weather forcing and half-hour solar
          data from a fully coupled case for the atmosphere. This is meant to spinup the
          CN BGC model.</para></listitem>
-->
       <listitem><para><varname>I_1948-2004_CN</varname> for 2000 AD simulation year running with CN BGC model
          with atmospheric data from 1948 to 2004.</para></listitem>
       <listitem><para><varname>I_1850-2000_CN</varname> for 20th Century simulations varying the vegetation
          types from 1850 to 2000 AD running with the CN BGC model
          with atmospheric data from 1948 to 2004.</para></listitem>
</orderedlist>
</sect2>

<sect2 id="EF_compsets">
     <title>Compsets coupled to active atmosphere with data ocean</title>
<para>
       CAM compsets are compsets that start with "E" or "F" in the name. They are
       described more fully in the scripts documentation or the CAM documentation. "E" compsets have
a slab ocean model while "F" compsets have a data ocean model.
</para>
</sect2>

<sect2 id="B_compsets">
<title>Fully coupled compsets with fully active ocean, sea-ice, and atmosphere</title>
<para>
       Fully coupled compsets are compsets that start with "B" in the name. They are
       described more fully in the scripts documentation.
</para>
</sect2>

<sect2 id="chose_compset_conclude">
<title>Conclusion to choosing a compset</title>
<para>
We've introduced the basic type of compsets that use CLM and given some further details
for the "standalone CLM" (or "I" compsets).  The 
<ulink url="./../../../../scripts/ccsm_utils/Case.template/config_compsets.xml">
config_compsets.xml</ulink> lists all of the compsets and gives a full description
of each of them. In the next section we look into customizing the configure time options
for compsets using CLM.
</para>
</sect2>
</sect1>
<!-- End of choosing a compset section -->

<!-- Beg of customizing clm config section -->
<sect1 id="customizing_clm_config">
<title>Customizing the clm configuration</title>
<para>
The "Creating a Case" section of the 
<ulink url="http://www.ccsm.ucar.edu/models/ccsm4.0/ccsm/ccsm_doc/book1.html">CCSM4.0 Scripts Users-Guide</ulink>
gives instructions on creating a case. What is of interest here is how to customize your use of clm
for the case that you created. In this section we discuss how to customize your case before the first
step -- the "configure -case" step is done. in the next section we will discuss how to customize your
clm namelist after "configure -case" has already been done.
</para>
<para>
For CLM when "configure -case" is called there are two steps that take place:
</para>
<orderedlist>
<listitem><para>The clm "configure" script is called to setup the build-time configuration for clm.</para></listitem>
<listitem><para>The clm "build-namelist" script is called to generate  the initial run-time namelist for clm.</para></listitem>
</orderedlist>
<para>
When customizing your case at the configure step you are able to modify the process by effecting either one
or both of these steps. The clm "configure" and "build-namelist" scripts are both available in the "models/lnd/clm/bld" 
directory in the distribution. Both of these scripts have a "-help" option that is useful to examine to see what
types of options you can give either of them.
</para>
<para>
There are five different types of customization for the configuration that we will 
discuss: CCSM4 CLM configuration items, Configure time User Namelist,
other noteworthy CCSM configuration items, the CLM configure script options, and 
the CLM build-namelist script options.
</para>

<sect2 id="clm_script">
<title>CLM Script configuration items</title>
<para>
Below we list each of the CCSM configuration items that are specific to CLM.
</para>
<para>
<simplelist>
    <member><varname>CLM_CONFIG_OPTS</varname></member>
    <member><varname>CLM_BLDNML_OPTS</varname></member>
    <member><varname>CLM_NAMELIST_OPTS</varname></member>
    <member><varname>CLM_FORCE_COLDSTART</varname></member>
    <member><varname>CLM_PT1_NAME</varname></member>
    <member><varname>CLM_USRDAT_NAME</varname></member>
</simplelist>
</para>
<para>
The first item "CLM_CONFIG_OPTS" has to do with customizing the CLM configuration options for your case, the rest
all have to do with generating the initial namelist.
</para>
<para>
CLM_CONFIG_OPTS
</para>
<para>
The option "CLM_CONFIG_OPTS" is all about passing command line arguments to the CLM configure script. It is important
to note that some compsets, may already put a value into the CLM_CONFIG_OPTS variable. You can still add more
options to your "CLM_CONFIG_OPTS" but make sure you add to what is already there rather than replacing it. Hence,
it may be best to edit the "env_conf.xml" file to do this rather than use the xmlchange script. In the 
section below we will go into more details on options that can be customized in the CLM "configure" script. It's
also important to note that the clm template may already invoke certain CLM configure options and as such those
command line options are NOT going to be available to change at this step (nor would you want to change them).
</para>
<para>
CLM_NML_USE_CASE
</para>
<para>
"CLM_NML_USE_CASE" is used to set a particular set of conditions that set multiple namelist items, all centering around
a particular usage of the model.
To list the valid options do the following:
</para>
<screen>
> cd models/lnd/clm/bld
> build-namelist -use_case list
</screen>
<para>
CLM_BLDNML_OPTS
</para>
<para>
The option "CLM_BLDNML_OPTS" is for passing options to the CLM "build-namelist" script. As with the "configure"
script the clm template may already invoke certain options and as such those options will NOT be available to be
set here. The best way to see what options can be sent to the "build-namelist" script is to do
</para>
<screen>
> cd models/lnd/clm/bld
> build-namelist -help
</screen>
<para>
The clm template already sets the resolution and mask as well as the configure file, the start-type, and defines a input
namelist and namelist input file, and it normally sets either "-ignore_ic_year" or "-ignore_ic_date". Also many
of the options are designed solely for CLM stand-alone testing and hence should NOT be used (any of the options starting
with a "datm_" or "drv_" prefix. Hence there are then only four different options that could be set:
</para>
<para>
<orderedlist>
<listitem><para>-lnd_res</para></listitem>
<listitem><para>-sim_year</para></listitem>
<listitem><para>-rcp</para></listitem>
<listitem><para>-clm_demand</para></listitem>
<listitem><para>-verbose</para></listitem>
</orderedlist>
</para>
<para>
"-lnd_res" is used to run CLM at a higher resolution than it is coupling to the atmospheric model. This can
be useful to get more accuracy from the land model by running at a higher resolution, but saving computer time
by running the more expensive atmospheric model at a lower resolution. To get a list of valid resolutions to
run at do the following:
</para>
<screen>
> cd models/lnd/clm/bld
> build-namelist -lnd_res list
</screen>
<para>
"-clm_demand" asks the build-namelist step to require that the list of variables
entered be set. Typically, this is used to require that optional filenames be used and ensure
they are set before continuing. For example, you may want to require that
<varname>fpftdyn</varname> be set to get dynamically changing vegetation types. To do this
you would do the following.
<screen>
> xmlchange -file env_conf.xml -id CLM_BLDNML_OPTS -val "-clm_demand fpftdyn"
</screen>
To see a list of valid variables that you could set do this:
<screen>
> cd models/lnd/clm/bld
> build-namelist -clm_demand list
</screen>
</para>
<note>
 <para>
Using a 20th-Century transient compset or the <envar>20thC_transient</envar> use-case
using <envar>CLM_NML_USE_CASE</envar> would set this as well, but would also use 
fndepdyn, and dynamic faerdep files, so using <envar>-clm_demand</envar> would be a way 
to get <emphasis>just</emphasis> dynamic vegetation types and NOT the other files as well.
</para>
</note>
<para>
"-sim_year" is used to set the simulation year you want the data-sets to simulate conditions for in the input
datasets. To list the valid options do the following:
</para>
<screen>
> cd models/lnd/clm/bld
> build-namelist -sim_year list
</screen>
<para>
"-rcp" is used to set the representative concentration pathway for the future scenarios
you want the data-sets to simulate conditions for, in the input
datasets. To list the valid options do the following:
</para>
<screen>
> cd models/lnd/clm/bld
> build-namelist -rcp list
</screen>
<para>
CLM_NAMELIST_OPTS
</para>
<para>
The option <envar>CLM_NAMELIST_OPTS</envar> is for passing namelist items into the "clm_inparm" namelist.
Any items that are set in CLM_NAMELIST_OPTS will be set in your namelist after "configure
-case" is done.
</para>
<note>
<para>
For character namelist items you need to use "&amp;apos;" as quotes for strings so that the 
scripts don't get confused with other quotes they use.
</para>
</note>
<para>
Example, you want to set <varname>hist_dov2xy</varname> to <varname>.false.</varname>
so that you get vector output to your history files. You want to edit
<filename>env_conf.xml</filename> and add a setting for <varname>hist_dov2xy</varname>.
So do the following:
<screen>%xmlchange -file env_conf.xml -id CLM_NAMELIST_OPTS -val hist_dov2xy=.false.</screen>
</para>
<para>
CLM_CO2_TYPE
</para>
<para>
<envar>CLM_CO2_TYPE</envar>
</para>
<para>
CLM_FORCE_COLDSTART
</para>
<para>
<envar>CLM_FORCE_COLDSTART</envar> when set to <emphasis><envar>on</envar></emphasis> <emphasis>requires</emphasis> that
your simulation do a cold start from arbitrary initial conditions. If this is NOT set, it
will use an initial condition file if it can find an appropriate one, and otherwise do a cold
start. <envar>CLM_FORCE_COLDSTART</envar> is a good way to ensure that you are doing a cold
start if that is what you want to do.
</para>
<para>
CLM_PT1_NAME
</para>
<para>
<envar>CLM_PT1_NAME</envar> is used <emphasis>ONLY</emphasis> for a <varname>pt1_pt1</varname>
resolution simulation to set the name of the single-point files to use.
To see a list of the valid resolutions do this:
<screen>
> cd models/lnd/clm/
> build-namelist -res list
</screen>
the valid resolutions that can be used with <envar>CLM_PT1_NAME</envar> are the ones that
have city or nation names such as: 5x5_amazon, 1x1_vancouverCAN 1x1_mexicocityMEX, or
1x1_brazil. The "1x1_" prefix means the file is for a single-point, while "5x5_" prefix means
it's for a region of five points in latitude by five points in longitude. Both regional an
single point datasets can be used for CLM_PT1_NAME.
</para>
<para>
CLM_USR_DATNAME
</para>
<para>
<envar>CLM_USR_DATNAME</envar> provides a way to enter your own datasets into the initial
namelist setup at "configure -case". The files you create must be named with
See the <ulink url="../Quickstart.userdatasets">Quickstart.userdatasets</ulink> 
file describing the steps do use your own datasets, for more details on each step.
To see what the expected names of the files are use, queryDefaultNamelist.pl to see
what the names will need to be. For example if you <envar>CLM_USR_DATNAME</envar> will 
be "1x1_boulderCO", with a "navy" land-mask, constant simulation year range, for 1850,
the following will list what your filenames should be:
<screen>
> cd models/lnd/clm/bld
> queryDefaultNamelist.pl -usrname "1x1_boulderCO" -options
mask=navy,sim_year=1850,sim_year_range="constant"  -csmdata $CSMDATA
</screen>
</para>

</sect2>

<sect2 id="config_time_nml">
<title>Configure time User Namelist</title>
<para>
<envar>CLM_NAMELIST_OPTS</envar> as described above allows you to set any
extra namelist items you would like to appear in your namelist after first configured.
However, it only allows you a single line to enter namelist items, and strings must
be quoted with &amp;apos; which is a bit awkward. If you have a long list of namelist
items you want to set (such as a long list of history fields) a convienent way to do it
is to create a <filename>user_nl_clm</filename> that contains just the list of namelist
variables you want to add to your initial namelist. The <filename>user_nl_clm</filename>
will only be used when configure is run, so if you change it after configure -- it won't
change anything. The file needs to be in valid FORTRAN namelist format, and the configure
step will abort if there are syntax errors. The namelist name actually doesn't have to be
valid, but all the variable names must be. Here's an example <filename>user_nl_clm</filename>
namelist that sets a bunch of history file related items, to create output history files
monthly, daily, every six and 1 hours.
<screen>
&amp;clmexp
 hist_fincl2    = 'TG','TBOT','FIRE','FIRA','FLDS','FSDS',
                  'FSR','FSA','FGEV','FSH','FGR','TSOI',
                  'ERRSOI','BUILDHEAT','SABV','SABG',
                  'FSDSVD','FSDSND','FSDSVI','FSDSNI',
                  'FSRVD','FSRND','FSRVI','FSRNI',
                  'TSA','FCTR','FCEV','QBOT','RH2M','H2OSOI',
                  'H2OSNO','SOILLIQ','SOILICE', 
                  'TSA_U', 'TSA_R',
                  'TREFMNAV_U', 'TREFMNAV_R',
                  'TREFMXAV_U', 'TREFMXAV_R',
                  'TG_U', 'TG_R',
                  'RH2M_U', 'RH2M_R',
                  'QRUNOFF_U', 'QRUNOFF_R',
                  'SoilAlpha_U',
                  'Qanth', 'SWup', 'LWup', 'URBAN_AC', 'URBAN_HEAT'
  hist_fincl3 = 'TG:I', 'FSA:I', 'SWup:I', 'URBAN_AC:I', 'URBAN_HEAT:I',
                'TG_U:I', 'TG_R:I',
  hist_fincl4 = 'TG', 'FSA', 'SWup', 'URBAN_AC', 'URBAN_HEAT'
  hist_mfilt  = 1, 30,  28, 24
  hist_nhtfrq = 0, -24, -6, -1
/
</screen>
Obviously, all of this would be difficult to put in the <envar>CLM_NAMELIST_OPTS</envar>
variable, especially having to put &amp;apos; around all the character strings. For
more information on the namelist variables being set here and what they mean, see
the section on CLM namelists below, as well as the namelist definition that gives
details on each variable.
</para>
</sect2>

<sect2 id="other_config">
<title>Other noteworthy configuration items</title>
<para>
For running "I" cases there are several other noteworthy configuration items that
you may want to work with. Most of these involve settings for the DATM, but one
<varname>CCSM_CO2_PPMV</varname> is a overall setting. If you are running an B, E,
or F case that doesn't use the DATM obviously these will not be important.
    <simplelist>
    <member><varname>CCSM_CO2_PPMV</varname></member>
    <member><varname>DATM_MODE</varname></member>
    <member><varname>DATM_CLMNCEP_YR_ALIGN</varname></member>
    <member><varname>DATM_CLMNCEP_YR_START</varname></member>
    <member><varname>DATM_CLMNCEP_YR_END</varname></member>
<!--
    <member><varname>DATM_CO2_TSERIES</varname></member>
-->
    </simplelist>
</para>
<variablelist>
<varlistentry>
<term>CCSM_CO2_PPMV</term> <listitem> 
<para>
<envar>CCSM_CO2_PPMV</envar> sets the mixing ratio of CO<subscript>2</subscript> in 
parts per million by volume for ALL CCSM components to use. Note that most compsets
already set this value to something reasonable. Also note that some compsets may
tell the atmosphere model to override this value with either historic or ramped 
values. If the <envar>CCSM_BGC</envar> variable is set to something other than "none"
the atmosphere model will determine CO<subscript>2</subscript>, and CLM will listen
and use what the atmosphere sends it. On the CLM side the namelist item <varname>
co2_type</varname> tells CLM to use the value sent from the atmosphere rather than
a value set on it's own namelist.
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>DATM_MODE</term><listitem>
<para>
<envar>DATM_MODE</envar> sets the mode that the DATM model should run in this determines
how data is handled as well as what the source of the data will be. Many of the modes
are setup specifically to be used for ocean and/or sea-ice modeling. The modes
that are designed for use by CLM are:
<simplelist>
<member>CLM_QIAN</member>
<member>CLM1PT</member>
<!--
<member>CPLHIST3HrWx</member>
<member>CPLHIST3HrWxHfHrSol</member>
-->
</simplelist>
</para>
<para>
<varname>CLMQIAN</varname> is for the standard mode of using global atmospheric data 
that was developed by Qian et. al. for CLM using NCEP data from 1948 to 2004.
<varname>CLM1PT</varname> is for the special cases where we have single-point tower
data for particular sites. Right now we only have data for three urban locations:
MexicoCity, Mexico, Vancouver Canada, and the urban-c alpha site. This is non-standard
functionality and we recommend that users stick with the CLMQIAN mode of operation.
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>DATM_CLMNCEP_YR_START</term><listitem>
<para>
<envar>DATM_CLMNCEP_YR_START</envar> sets the beginning year to cycle the atmospheric
data over for the CLMQIAN mode.
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>DATM_CLMNCEP_YR_END</term><listitem>
<para>
<envar>DATM_CLMNCEP_YR_END</envar> sets the ending year to cycle the atmospheric
data over for the CLMQIAN mode.
</para>
</listitem>
</varlistentry>
<varlistentry>
<term>DATM_CLMNCEP_YR_ALIGN</term><listitem>
<para>
<envar>DATM_CLMNCEP_YR_START</envar> and <envar>DATM_CLMNCEP_YR_END</envar> determine
the range of years to cycle the atmospheric data over, and <envar>DATM_CLMNCEP_YR_ALIGN</envar>
determines which year in that range of years the simulation will start with.
</para>
</listitem>
</varlistentry>
<!--
<varlistentry>
<term>DATM_CO2_TSERIES</term><listitem>
<para>
....
</para>
</listitem>
</varlistentry>
-->
</variablelist>
<para>
The configure script defines the details of a clm configuration and summarizes it into a
<filename>config_cache.xml</filename> file. The
<ulink url="../../bld/config_files/config_definition.xml">config_definition.xml</ulink>
gives a definition of each clm configuration item. Many of these items are things that you
would NOT change, but looking through the list gives you the valid options, and a good
description of each. Coupling this with looking at the options to configure with
"models/lnd/clm/bld/configure -help" will enable you to understand how to set the different
options.
</para>
<para>
We've given details on how to use the options in <filename>env_conf.xml</filename> to
interact with the CLM "configure" and "build-namelist" scripts. As well as giving a good
understanding of how these scripts work and the options to them. In the next section we
give further details on the clm namelist. You could customize the namelist for these 
options after "configure -case" is run, or you could customize it using the
<envar>CLM_BLDNML_OPTS</envar> which we described here.
</para>
</sect2>
</sect1>
<!-- End of customizing clm config section -->

<!-- Beg of customizing clm nl section -->
<sect1 id="customizing_clm_nl">
   <title>Customizing the clm namelist</title>
<para>
Once a case is configured, we can then customize the case further, by editing the 
run-time namelist for CLM. First let's list the definition of each namelist
item and their valid values, and then we'll list the default values for them.
Next for some of the most used or tricky namelist items we'll give examples of their
use, and give you example namelists that highlight these features.
</para>

<!-- Beg of nl definition section -->
<sect2 id="nl_def">
<title>Definition of Namelist items and their default values</title>
<para>
Here we give the definition of each namelist item and separately the default values for
them. The default values may change depending on the resolution, land-mask, simulation-year
and other attributes.
</para>
<orderedlist>
<listitem><para>
<ulink url="../../bld/namelist_files/namelist_definition.xml">Definition of each Namelist Item</ulink>
</para></listitem>
<listitem><para>
<ulink url="../../bld/namelist_files/namelist_defaults_clm.xml">Default values of each CLM Namelist Item</ulink>
</para></listitem>
</orderedlist>
</sect2>
<!-- End of nl definition section -->

<sect2 id="nl_def_conclude">
<title>Namelist definition Conclusion</title>
<para>
We've given the definition of each namelist item, and the default values that the CLM
"build-namelist" script will use for them. In the next section we give examples of using
selected namelist features.
</para>
</sect2>

<!-- Beg of nl examples section -->
<sect2 id="nl_examples">
<title>Examples of using different namelist features</title>
<para>
Below we will give examples of user namelists that activate different commonly used
namelist features. We will discuss the namelist features in different examples and then
show a user namelist that includes an example of the use of these features. First we
will show the default namelist that doesn't activate any user options.
</para>

<sect3 id="default_nml">
<title>The default namelist</title>
<para>
Here we give the default namelist as it would be created for a I1850CN compset at 0.9x1.25
resolution with a gx1v6 land-mask. To edit the namelist you would edit the
<filename>BuildConf/clm.buildnml.csh</filename> under your case (or before configure
include a user namelist with just the items you want to change). For simplicity we will
just show the namelist and NOT the entire file. In the sections below, for simplicity
 we will just show the user namelist (user_nl_clm) that will add (or modify existing) 
namelist items to the namelist.
<screen>
&amp;clm_inparm
 co2_ppmv               = 284.7
 co2_type               = 'constant'
 dtime          = 1800
 faerdep                =
'$DIN_LOC_ROOT/atm/cam/chem/trop_mozart_aero/aero/aerosoldep_monthly_1850_0.9x1.25_c090828.nc'
 fatmgrid               = '$DIN_LOC_ROOT/lnd/clm2/griddata/griddata_0.9x1.25_070212.nc'
 fatmlndfrc             =
'$DIN_LOC_ROOT/lnd/clm2/griddata/fracdata_0.9x1.25_gx1v6_c090317.nc'
 finidat                =
'$DIN_LOC_ROOT/lnd/clm2/initdata/clmi.BCN.0400-01-01_0.9x1.25_gx1v6_simyr1850_c091016.nc'
 fndepdat               =
'$DIN_LOC_ROOT/lnd/clm2/ndepdata/ndep_clm_simyr1850_0.9x1.25_c091106.nc'
 fpftcon                = '$DIN_LOC_ROOT/lnd/clm2/pftdata/pft-physiology.c081222'
 frivinp_rtm            = '$DIN_LOC_ROOT/lnd/clm2/rtmdata/rdirc.05.061026'
 fsnowaging             =
'$DIN_LOC_ROOT/lnd/clm2/snicardata/snicar_drdt_bst_fit_60_c070416.nc'
 fsnowoptics            =
'$DIN_LOC_ROOT/lnd/clm2/snicardata/snicar_optics_5bnd_c090915.nc'
 fsurdat                =
'$DIN_LOC_ROOT/lnd/clm2/surfdata/surfdata_0.9x1.25_urb3den_simyr1850_c090702.nc'
 hist_crtinic           = 'NONE'
 hist_mfilt             = 1
 hist_nhtfrq            = 0
 nrevsn         = ' '
 outnc_large_files              = .true.
 rtm_nsteps             = 6
 urban_hac              = 'ON_WASTEHEAT'
 urban_traffic          = .false.
/
</screen>
Note that the namelist introduces some of the history namelist options that will be
talked about in further detail below (<varname>hist_mfilt</varname> and
<varname>hist_nhtfrq</varname>).
</para>
</sect3>

<sect3 id="add_rm_primary_hist">
<title>Adding/removing fields on your primary history file</title>
<para>
The primary history files are output monthly, and contain an extensive list of
fieldnames, but the list of fieldnames can be added to using <varname>hist_fincl1</varname>
or removed from by adding fieldnames to <varname>hist_fexcl1</varname>.
A sample user namelist <filename>user_nl_clm</filename> adding few new fields
(shortwave up, longwave up, and anthropogentic heat flux) and excluding a few 
standard fields is (ground temperature, vegetation temperature, soil temperature and soil water).:
<screen>
&amp;clm_inparm
 hist_fincl1 = 'SWup', 'LWup', 'Qanth'
 hist_fexcl1 = 'TG', 'TV', 'TSOI', 'H2OSOI'
/
</screen>
</para>
</sect3>

<sect3 id="add_aux_hist_chng_output_frq">
<title>Adding auxiliary history files and changing output
frequency</title>
<para>
The <varname>hist_fincl2</varname> through <varname>hist_fincl6</varname> set of
namelist variables add given history fieldnames to auxiliary history file "streams", and
<varname>hist_fexcl2</varname> through <varname>hist_fexcl6</varname> set of
namelist variables remove given history fieldnames from history file auxiliary "streams".
A history "stream" is a set of history files that are produced at a given frequency.
By default there is only one stream of monthly data files. To add more streams you
add history fieldnames to <varname>hist_fincl2</varname> through
<varname>hist_fincl6</varname>. The output frequency and the way averaging is done
can be different for each history file stream. By default the primary history files
are monthly and any others are daily. You can have up to six active history streams, but you need
to activate them in order. So if you activate stream "6" by setting
<varname>hist_fincl6</varname>, but if any of <varname>hist_fincl2</varname> through
<varname>hist_fincl5</varname> are unset, only the history streams up to the first blank one
will be activated.
</para>
<para>
The frequency of the history file streams is given by the namelist variable
<varname>hist_nhtfrq</varname> which is an array of rank six for each history stream.
The value of <varname>hist_nhtfrq</varname> can be integers, where the following values 
have the given meaning:
<simplelist>
<member><emphasis>Positive value</emphasis> means the output frequency is the number of
model steps between output.
</member>
<member><emphasis>Negative value</emphasis> means the output frequency is the absolute
value in hours given (i.e -1 would mean an hour and -24 would mean a full day). Daily
(-24) is the default value for all auxiliary files.
</member>
<member><emphasis>Zero</emphasis> means the output frequency is monthly. This is the
default for the primary history files.
</member>
</simplelist>
A sample user namelist <filename>user_nl_clm</filename> turning on four extra file
streams for output: daily, six-hourly, hourly, and every time-step, and 
leaving the primary history files for monthly is:
<screen>
&amp;clm_inparm
 hist_fincl2 = 'TG', 'TV'
 hist_fincl3 = 'TG', 'TV'
 hist_fincl4 = 'TG', 'TV'
 hist_fincl5 = 'TG', 'TV'
 hist_nhtfrq = 0, -24, -6, -1, 1
/
</screen>
</para>
</sect3>

<sect3 id="rm_hist">
<title>Removing all history fields</title>
<para>
Sometimes for various reasons you want to remove all the history fields either
because you want to do testing without any output, or you only want a very small
custom list of output fields rather than the default extensive list of fields.
By default only the primary history files are active, so technically using
<varname>hist_fexcl1</varname> explained in the first example, you could list 
<emphasis>ALL</emphasis> of the history fields that are output in 
<varname>hist_fexcl1</varname> and then you wouldn't get any output. However, as
the list is very extensive this would be a cumbersome thing to do. So to facilitate
this <varname>hist_empty_htapes</varname> allows you to turn off all default output.
You can still use <varname>hist_fincl1</varname> to turn your own list of fields
on, but you then start from a clean slate. 
A sample user namelist <filename>user_nl_clm</filename> turning off all history 
fields and then activating just a few selected fields (ground and vegetation temperatures
and abosrbed solar radiation) is:
<screen>
&amp;clm_inparm
 hist_empty_htapes = .true.
 hist_fincl1 = 'TG', 'TV', 'FSA'
/
</screen>
</para>
</sect3>

<sect3 id="hist_averaging">
<title>Various ways to change history output averaging flags</title>
<para>
There are two ways to change the averaging of output history fields. The first is using
<varname>hist_avgflag_pertape</varname> which gives a default value for each history
stream, the second is when you add fields using <varname>hist_fincl*</varname>, you add
an averaging flag to the end of the field name after a colon (for example 'TSOI:X', would
output the maximum of TSOI).
The types of averaging that can be done are:
<simplelist>
<member><emphasis>A</emphasis> Average, over the output interval.</member>
<member><emphasis>I</emphasis> Instantaneous, output the value at the output interval.</member>
<member><emphasis>X</emphasis> Maximum, over the output interval.</member>
<member><emphasis>M</emphasis> Minimum, over the output interval.</member>
</simplelist>

A sample user namelist <filename>user_nl_clm</filename> making the monthly output
fields all averages, and adding auxillary file streams for instantaneous (6-hourly), 
maximum (daily), minimum (daily), and average (daily). For some of the fields we
diverge from the per-tape value given and customize to some different type of 
optimization.
<screen>
&amp;clm_inparm
 hist_empty_htapes = .true.
 hist_fincl1 = 'TSOI:X', 'TG',   'TV',   'LWup',   'SWup', 'FSH', 'EFLX_LH_TOT', 'WT'
 hist_fincl2 = 'TSOI:X', 'TG',   'TV',   'LWup',   'SWup', 'FSH', 'EFLX_LH_TOT', 'WT'
 hist_fincl3 = 'TSOI',   'TG:I', 'TV',   'LWup',   'SWup', 'FSH', 'EFLX_LH_TOT', 'WT'
 hist_fincl4 = 'TSOI',   'TG',   'TV:I', 'LWup',   'SWup', 'FSH', 'EFLX_LH_TOT', 'WT'
 hist_fincl5 = 'TSOI',   'TG',   'TV',   'LWup:I', 'SWup', 'FSH', 'EFLX_LH_TOT', 'WT'
 hist_avgflag_pertape = 'A', 'I', 'X',   'M', 'A'
 hist_nhtfrq = 0, -6, -24, -24, -24
/
</screen>
</para>
<para>
In the example we put the same list of fields on each of the tapes: soil-temperature,
ground temperature, vegetation temperature, Longwave radiation upwards, shortwave
radiation upwards, sensible heat, total latent-heat, and total water storage. We also
modify the soil-temperature for the primary and secondary auxillary tapes by outputing
them for a maximum instead of the default per-tape of average and instantaneous
respectively. For the tertiary auxillary tape we output ground temperature instantaneous
instead of as a maximum, and for the fourth auxillary tape we output vegetation
temperature instantaneous instead of as a maximum. Finally, for the fifth auxillary
tapes we output <varname>LWup</varname> instanteously instead of as an average.
</para>
<note>
<para>
We also use <varname>hist_empty_htapes</varname> as in the previous example,
so we can list ONLY the fields that we want on the primary history tapes.
</para>
</note>
</sect3>

<sect3 id="hist_vector">
<title>Outputting history files as a vector in order to analyze
the plant function types within gridcells</title>
<para>
By default the output to history files are the grid-cell average of all land-units, and
vegetation types within that grid-cell, and output is on the
full 2D latitude/longitude grid with ocean masked out. Sometimes it's important to
understand how different land-units or vegetation types are acting within a grid-cell.
The way to do this is to output history files as a 1D-vector of all land-units and vegetation
types. In order to display this, you'll need to do extensive post-processing to make sense
of the output. Often you may only be interested in a few points, so once you figure out the
1D indices for the grid-cells of interest, you can easily view that data. 1D vector output
can also be useful for single point datasets, since it's then obvious that all data is for the
same grid cell.
</para>
<para>
To do this you use <varname>hist_dov2xy</varname> which is an array of six six for each history stream. Set it to
<varname>.false.</varname> if you want one of the history streams to be a 1D vector. 
You can also use <varname>hist_type1d_pertape</varname> if you want to average over all the:
Plant-Function-Types, columns, land-units, or grid-cells.
A sample user namelist <filename>user_nl_clm</filename> leaving the primary monthly
files as 2D, and then doing grid-cell, land-unit, column, PFT and no averaging over
auxillary tapes output daily for a single field (ground temperature) is:
<screen>
&amp;clm_inparm
 hist_fincl2 = 'TG'
 hist_fincl3 = 'TG'
 hist_fincl4 = 'TG'
 hist_fincl5 = 'TG'
 hist_fincl6 = 'TG'
 hist_dov2xy = .false., .true., .true., .true., .true., .true.
 hist_type2d_pertape = ' ', 'GRID', 'LAND', 'COLS', 'PFTS', ' '
 hist_nhtfrq = 0, -24, -24, -24, -24, -24
/
</screen>
</para>
<note>
<para>
Technically the default for <varname>hist_nhtfrq</varname> is for primary files
output monthly and the other auxillary tapes for daily, so we don't actually have
to include <varname>hist_nhtfrq</varname>, we could use the default for it. Here
we specify it for clarity.
</para>
</note>
<note>
<para>
Visuallizing global 1D vector files will take effort. You'll probably want
to do some postprocessing and possibly just extract out single points of interest
to see what is going on. Since, the output is a 1D vector, of only land-points
traditional plots won't be helpful. The number of points per grid-cell will also
vary for anything, but grid-cell averaging.
</para>
</note>
</sect3>

<sect3 id="nl_example_conclude">
<title>Conclusion to namelist examples</title>
<para>
We've given various examples of namelists that feature the use of different namelist options
to customize a case for particular uses. Most the examples revolve around how to customize the
output history fields. This should give you a good basis for setting up your own CLM namelist.
</para>
</sect3>
</sect2>
<!-- End of nl examples section -->

</sect1>
<!-- End of customizing clm nl section -->

<sect1 id="customizing_conclude">
<title>Conclusion to customizing chapter</title>
<para>
We've given extensive details on customizing cases with CLM, by choosing compsets, by changing
configure options and interacting with the CLM "configure" and "build-namelist" scripts, and
finally we've given details on all of the CLM namelist items. In the next chapter we talk
about further ways to customize cases with CLM by creating your own datasets using the tools
provided in CLM.
</para>
</sect1>
</chapter>
<!-- End of customizing chapter -->

<!-- Beg of tools chapter -->
<chapter id="tools">
<title>Using the CLM tools to create your own input datasets</title>
<para>
There are several tools provided with CLM that allow you to create your own input 
datasets at resolutions you choose, or to interpolate initial conditions to a different
resolution, or used to compare CLM history files between different cases. The tools are
all available in the <filename>models/lnd/clm/tools</filename> directory. Most of the tools
are FORTRAN stand-alone programs in their own directory, but there is also a suite of NCL
scripts in the <filename>ncl_scripts</filename> directory. Some of the NCL scripts are
very specialized and not meant for general use, and we won't document them here. They
still contain documentation in the script itself and the README file in the tools
directory. But, the list of generally important scripts and programs are:
<orderedlist>
<listitem>
<para> <emphasis>cprnc</emphasis> to compare NetCDF files with a time axis.</para>
</listitem>
<listitem>
<para> <emphasis>interpinic</emphasis> to interpolate initial condition files.</para>
</listitem>
<listitem>
<para> <emphasis>mkgriddata</emphasis> to create grid datasets.</para>
</listitem>
<listitem>
<para> <emphasis>mkdatadomain</emphasis> to create domain files from grid datasets
used by datm or docn.</para>
</listitem>
<listitem>
<para> <emphasis>mksurfdata</emphasis> to create surface datasets from grid datasets.</para>
</listitem>
<listitem>
<para> <emphasis>ncl_scripts/getregional_datasets.pl</emphasis> script to extract a
region or a single-point from global input datasets. See the single-point chapter
for more information on this.</para>
</listitem>
<listitem>
<para> <emphasis>ncl_scripts/npdepregrid.ncl</emphasis> interpolate the Nitrogen
deposition datasets to a new resolution.</para>
</listitem>
<listitem>
<para> <emphasis>ncl_scripts/aerdepregrid.ncl</emphasis> interpolate the Aerosol
deposition datasets to a new resolution.</para>
</listitem>
</orderedlist>
</para>

<sect1 id="tool_build">
<title>Common environment variables and options used in building the FORTRAN
tools</title>
<para>
The FORTRAN tools all have similar makefiles, and similar options for building.
All of the Makefiles use GNU Make extensions and thus require that you use GNU make
to use them. They also auto detect the type of platform you are on, using "uname -s"
and set the compiler, compiler flags and such accordingly. There are also environment
variables that can be set to set things that must be customized. All the tools use
NetCDF and hence require that the path to the NetCDF libraries and include files.
On some platforms (such as Linux) multiple compilers can be used, and hence there
are env variables that can be set to change the FORTRAN and/or "C" compilers used.
The tools other than "cprnc" also  allow finer control, by also allowing the user to
add compiler flags they choose for both "C" and FORTRAN compilers and set the linker 
and add linker options. Finally the tools other than "cprnc" allow you to turn
optimization on (which is off by default) with the <envar>OPT</envar> flag so that the 
tool will run faster. To get even faster performance, the interpinic program allows 
you to also use the <envar>SMP</envar> to turn on multiple shared memory processors.
When <envar>SMP=TRUE</envar> you set the number of threads used by the program with
the <envar>OMP_NUM_THREADS</envar> environment variable.
</para>
<para>
Options used by all: cprnc, interpinic, mkdatadomain, mkgriddata, and mksurfdata
<simplelist>
<member><envar>LIB_NETCDF</envar> -- sets the location of the NetCDF library.</member>
<member><envar>INC_NETCDF</envar> -- sets the location of the NetCDF include files.</member>
<member><envar>USER_FC</envar> -- sets the name of the FORTRAN compiler.</member>
</simplelist>
Options used by: interpinic, mkdatadomain, mkgriddata, and mksurfdata
<simplelist>
<member><envar>MOD_NETCDF</envar> -- sets the location of the NetCDF FORTRAN module.</member>
<member><envar>USER_LINKER</envar> -- sets the name of the linker to use.</member>
<member><envar>USER_CPPDEFS</envar> -- adds any CPP defines to use.</member>
<member><envar>USER_CFLAGS</envar> -- add any "C" compiler flags to use.</member>
<member><envar>USER_FFLAGS</envar> -- add any FORTRAN compiler flags to use.</member>
<member><envar>USER_LDFLAGS</envar> -- add any linker flags to use.</member>
<member><envar>USER_CC</envar> -- sets the name of the "C" compiler to use.</member>
<member><envar>OPT</envar> -- set to TRUE to compile the code optimized (TRUE or FALSE)</member>
</simplelist>
Options used only by interpinic:
<simplelist>
<member><envar>SMP</envar> -- set to TRUE to turn on shared memory parallelism (i.e.
OpenMP) (TRUE or FALSE)</member>
</simplelist>
Options used only by cprnc:
<simplelist>
<member><envar>EXEDIR</envar> -- sets the location where the executable will be built.</member>
<member><envar>VPATH</envar> -- colen delimited path list to find the source files.</member>
</simplelist>
More details on each environment variable.
<simplelist>
<member><envar>LIB_NETCDF</envar></member>
<member><envar>INC_NETCDF</envar></member>
<member><envar>USER_FC</envar></member>
<member><envar>MOD_NETCDF</envar></member>
<member><envar>USER_LINKER</envar></member>
<member><envar>USER_CPPDEFS</envar></member>
<member><envar>USER_CFLAGS</envar></member>
<member><envar>USER_FFLAGS</envar></member>
<member><envar>USER_LDFLAGS</envar></member>
<member><envar>USER_CC</envar></member>
<member><envar>SMP</envar></member>
<member><envar>OPT</envar></member>
</simplelist>
"cprnc" unlike the other CLM tools doesn't need any outside code to operate. The
other tools are use some code outside their directory that is in the CCSM
distribution (either csm_share code or clm source code). They all have a 
<filename>Filepath</filename> file to set the location of the source code
directories that will be used. The "cprnc" program uses the <envar>VPATH</envar>
variable instead to do the same function.
</para>
</sect1>

<sect1 id="cprnc">
<title>Using the cprnc tool to compare two history files</title>
<para>
"cprnc" is a tool shared by both CAM and CLM to compare two NetCDF history files.
It differences every field that has a time-axis that is also shared on both files,
and reports a summary of the difference. The summary includes the three largest 
differences, as well as the root mean square (RMS) difference. It also gives some
summary information on the field as well. You have to enter at least one file, and up to
two files. With one file it gives you summary information on the file, and with two it
gives you information on the differences between the two. At the end it will give you a
summary of the fields compared and how many fields were different and how many were
identical.
</para>
<para>
Options:
<simplelist>
<member>-m = do NOT align time-stamps before comparing</member>
<member>-v = verbose output</member>
<member>-ipr</member>
<member>-jpr</member>
<member>-kpr</member>
</simplelist>
See the "cprnc"
<ulink url="../../tools/cprnc/README">README</ulink> file for more details.
</para>
</sect1>

<sect1 id="interpinic">
<title>Using interpinic to interpolate initial conditions to different
resolutions</title>
<para>
"interpinic" is used to interpolate initial conditions from one resolution to another.
In order to do the interpolation you must first run CLM to create a restart file to
use as the "template" to interpolate into. Running from arbitrary initial conditions
(i.e. finidat = ' ') for a single time-step is sufficient to do this. Make sure the
model produces a restart file. You also need to make sure that you setup the same
configuration that you want to run the model with, when you create the template file.
Options:
<simplelist>
<member>-i = Input filename to interpolate from</member>
<member>-o = Output interpolated file, and starting template file</member>
</simplelist>
</para>
</sect1>

<sect1 id="mkgriddata">
<title>Using mkgriddata to create grid datasets</title>
<para>
"mkgriddata" is used to create grid, fraction and topography datasets to run CLM
at a new resolution. It is typically the first step in creating datasets needed
to run CLM at a new resolution (followed by mksurfdata, and then the interpolation
programs, aerdepregrid, ndepregrid when running with CN).
</para>
<para>
There are three different major modes for using "mkgriddata" to create grid files
for CLM:
<simplelist>
<member>Convert CCSM domain files to CLM grid files</member>
<member>Convert CAM files to CLM grid files</member>
<member>Create single point or regional area grid files</member>
</simplelist>
</para>

<sect2 id="mkgridata_from_domainfile">
<title>Convert CCSM domain files to CLM grid files</title>
<para>
CCSM domain files such as used for datm, include all the information
needed to create CLM grid files.
<screen>
</screen>
</para>
</sect2>

<sect2 id="mkgridata_from_camfile">
<title>Convert CAM files to CLM grid files</title>
<para>
Older CAM initial files included all the information needed to create CLM
grid files. Newer CAM files no longer include land fraction data. Hence you
can use CAM files to give you the grid coordinates, but you need other data
to give you the land-mask and topography.
<screen>
</screen>
</para>
</sect2>

<sect2 id="mkgridata_regional">
<title>Create single point or regional area grid files</title>
<para>
The process to create single-point or regional area CLM grid files is the same.
You enter the number of latitudes and longitudes you want on your output file and
the extent of the grid: North, East, South and West. You also tell "mkgriddata" that
you are entering a "regional" grid and you also enter the standard Navy orography
dataset (or your own orography file if desired). For a single point you simply
enter "1" for the number of latitudes and longitudes, but you still enter the
grid extent (of the single grid cell). Here is a sample regional namelist to create
a 5x5 regional grid over the Amazon:
<screen>
&amp;clmexp
 mksrf_fnavyoro="/fs/cgd/csm/inputdata/lnd/clm2/rawdata/mksrf_navyoro_20min.c010129.nc"
 mksrf_lsmlon = 5
 mksrf_lsmlat = 5
 mksrf_edgee = 303.75
 mksrf_edgew = 286.25
 mksrf_edges = -15.
 mksrf_edgen = -4.
/
</screen>
</para>
<note>
<para>
You should enter longitudes with values from 0 to 360 East.
</para>
</note>
</sect2>

<sect2 id="mkgriddata_nml">
<title>mkgriddata namelist</title>
<para>
Namelist options to mkgriddata include:
<simplelist>
<member><varname>mksrf_fnavyoro</varname> -- Navy orography file to use for land fraction
and surface heights.</member>
<member><varname>mksrf_frawtopo</varname> -- Raw topography file with just surface
heights.</member>
<member><varname>mksrf_fcamfile</varname> -- CAM initial conditions file with
land-fractions and topography</member>
<member><varname>mksrf_fclmgrid</varname> -- CLM grid file</member>
<member><varname>mksrf_fccsmdom</varname> -- CCSM domain file</member>
<member><varname>mksrf_fcamtopo</varname> -- CAM topography file</member>
<member><varname>mksrf_lsmlon</varname> -- number of longitude for regional grid</member>
<member><varname>mksrf_lsmlat</varname>number of latitudes for regional grid</member>
<member><varname>mksrf_edgen</varname> -- Northern edge for regional grid</member>
<member><varname>mksrf_edgee</varname> -- Southern edge for regional grid</member>
<member><varname>mksrf_edges</varname> -- Eastern edge for regional grid</member>
<member><varname>mksrf_edgew</varname> -- Western edge for regional grid</member>
</simplelist>
</para>
</sect2>

</sect1>

<sect1 id="mkdatadomain">
<title>Using mkdatadomain to create domain datasets for datm or docn from CLM grid datasets</title>
<para>
"mkdatadomain" is used to convert CLM grid and fraction datasets into domain datasets
that can be used by either the "datm" or "docn" models.
</para>
</sect1>

<sect1 id="mksurfdata">
<title>Using mksurfdata to create surface datasets from grid datasets</title>
<para>
"mksurfdata" is used to create surface-datasets from grid datasets and raw datafiles
at half-degree resolution to produce files that describe the surface characteristics
needed by CLM (fraction of grid cell covered by different land-unit types, and fraction
for different vegetation types, as well as things like soil color, and soil texture,
etc.).
</para>
</sect1>

<sect1 id="ndepregrid">
<title>Using ndepregrid.ncl to interpolate Nitrogen deposition datasets</title>
<para>
"ndepregrid.ncl" interpolates the Nitrogen deposition datasets from one resolution
to another.
</para>
</sect1>

<sect1 id="aerdepregrid">
<title>Using aerdepregrid.ncl to interpolate Aerosol deposition datasets</title>
<para>
"aerdepregrid.ncl" interpolates the Aerosol deposition datasets from one resolution.
</para>
</sect1>

<sect1 id="tools_conclude">
<title>Conclusion of tools description</title>
<para>
We've given a description of how to use the different tools with CLM to create
customized datasets.
</para>
</sect1>

</chapter>
<!-- End of tools chapter -->

<!-- Beg of special cases chapter -->
<chapter id="special_cases">
<title>How to run some special cases</title>
<para>
In this chapter we describe how to run some special cases that take more than one step
to do. The straightforward cases have compsets and/or build-namelist use-cases setup for
them or require simple editing of a single-case. All of the cases here require you
to do at least two simulations with different configurations.
</para>
<para>
The two cases we will describe are:
<orderedlist>
<listitem>
<para>
<emphasis>Spinning up the biogeochemistry Carbon-Nitrogen Model (CN spinup)</emphasis>
</para>
</listitem>
<listitem>
<para>
<emphasis>Doing perturbation error growth tests</emphasis>
</para>
</listitem>
</orderedlist>
</para>

<sect1 id="CN_SPINUP">
<title>Spinning up the biogeochemistry Carbon-Nitrogen Model (CN spinup)</title>
<para>
To get the CN model to a steady state, you first run it from arbitrary initial conditions
using the "accelerated decomposition spinup" (-ad_spinup in configure) mode for 600 simulation years. After
this you branch from this mode in the "exit spinup" (-exit_spinup in configure), run
for a simulation year, and then save a restart from that and use it as initial conditions 
for further spinup of CN (at least 50 simulation years).
</para>
<para>
For the first step of running 600 years in "-ad_spinup" mode, you will setup
a case, and then edit the values in <filename>env_conf.xml</filename> and
<filename>env_run.xml</filename> so that the right configuration is turned on and
the simulation is setup to run for the required length of simulation time.
So do the following:
<screen>
> cd scripts
> create_newcase -case CN_spinup -res f19_g16 -compset ICN -mach bluefire -skip_rundb
> cd CN_spinup
# Add "-ad_spinup on" to CLM_CONFIG_OPTS in env_conf.xml using your editor of choice
> $EDITOR env_conf.xml
# The following sets CLM_FORCE_COLDSTART to "on" in env_conf.xml (you could also use an editor)
> xmlchange -file env_conf.xml -id CLM_FORCE_COLDSTART -val on
# The following sets RESUBMIT to 30 times in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id RESUBMIT -val 30
# The following sets STOP_OPTION to "nyears" in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id STOP_OPTION -val nyears
# The following sets STOP_N to 20 years in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id STOP_N -val 20
# The following sets STOP_DATE to Jan/1 of year 600 in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id STOP_DATE -val 6000101
</screen>
Then configure your case and build and run it as normal. And then save the last restart
file from this simulation to use in the next step.
</para>
<para>
To exit the spinup up mode and create an initial condition file to do further
spinup with use "-exit_spinup" mode as follows:
<screen>
> cd scripts
> create_newcase -case CN_exitspinup -res f19_g16 -compset ICN -mach bluefire -skip_rundb
> cd CN_exitspinup
# Add "-exit_spinup on" to CLM_CONFIG_OPTS in env_conf.xml using your editor of choice
> $EDITOR env_conf.xml
> configure -case
# Set the finidat file to the last restart file saved in previous step
> $EDITOR BuildConf/clm.buildnml.csh
# The following sets STOP_OPTION to "nyears" in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id STOP_OPTION -val nyears
# The following sets STOP_N to one year in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id STOP_N -val 1
</screen>
</para>
<para>
Next save the last restart file from this step and use it as the "finidat" file to
use for one more spinup for at least 50 years in normal mode. To assess it the model
if fully spinup you'll want to plot different CN variables you are interested in and see
if they have any trend or not.
So do the following:
<screen>
> cd scripts
> create_newcase -case CN_finalspinup -res f19_g16 -compset ICN -mach bluefire -skip_rundb
> cd CN_finalspinup
# The following sets CLM_FORCE_COLDSTART to "on" in env_conf.xml (you could also use an editor)
> xmlchange -file env_conf.xml -id CLM_FORCE_COLDSTART -val on
# The following sets RESUBMIT to 5 times in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id RESUBMIT -val 5
# The following sets STOP_OPTION to "nyears" in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id STOP_OPTION -val nyears
# The following sets STOP_N to 10 years in env_run.xml (you could also use an editor)
> xmlchange -file env_run.xml -id STOP_N -val 10
> configure -case
# Set the finidat file to the last restart file saved in previous step
> $EDITOR BuildConf/clm.buildnml.csh
</screen>
</para>
<para>
Finally save the restart file from the end of this simulation to use as an "finidat" file for future
simulations.
</para>
</sect1>

<sect1 id="PERGRO">
<title>Doing perturbation error growth tests</title>
<para>
Doing perturbation error growth tests is a way to validate a port of
the model to a new machine or to verify that changes are only roundoff.
The steps are the same in either case, but in the discussion below I will
assume you are doing a port validation to a new machine (but in parenthesis 
I will put a reminder that it could also be for code-mods).
The basic idea is to do run two cases on the trusted machine (trusted code) and
one with initial conditions perturbed by roundoff and compare the results of
the two. The difference between these two simulations (the error) will grow over time
and describe a curve that we want to compare the non-perturbed state with the new
machine (code changes in place). If the new machine (code changes) are well-behaved
the plot of this curve compared to the perturbation growth curve should be similar. If the 
changes are NOT well-behaved the changes from the new machine (code changes) will be 
larger than the perturbation changes. In summary the simulations and steps that need to be performed are:
<orderedlist>
<listitem>
<para>Run a simulation with the trusted code on the trusted machine.</para>
</listitem>
<listitem>
<para>Run a simulation with the trusted code on the trusted machine with initial conditions
perturbed by roundoff (using a namelist item to do so).</para>
</listitem>
<listitem>
<para>Run a simulation with the new code on the non-trusted machine (code changes).</para>
</listitem>
<listitem>
<para>Do a plot of the RMS difference of TSOI between simulation 1 and simulation 2.</para>
</listitem>
<listitem>
<para>Do a plot of the RMS difference of TSOI between simulation 1 and simulation 3.</para>
</listitem>
<listitem>
<para>Compare the two plots in steps 4 and 5.</para>
</listitem>
<listitem>
<para>If the plots compare well the new machine (code changes) is running as well as the trusted machine.</para>
</listitem>
<listitem>
<para>If the plots do <emphasis>NOT</emphasis>compare well the new machine is
<emphasis>NOT</emphasis>running as well as the trusted machine. Typically the
recommendation here is to lower the optimization level on the new machine and try
again (or in the case of code changes, modify or simplify the code changes to get
something that should be closer).</para>
</listitem>
</orderedlist>
</para>
<para>
</para>
</sect1>
</chapter>
<!-- End of special cases chapter-->

<!-- Beg of single_point chapter-->
<chapter id="single_point">
<title>How to run Single-Point cases</title>
<para>
The CLM also allows you to set up and run cases with a single-point or a local region as well
as global resolutions. This is often useful for running quick cases for testing, evaluating
specific vegetation types, or land-units, or running with observed data for a specific site.
There are three different ways to do this: <envar>PTS_MODE</envar>,
<envar>CLM_1PT_NAME</envar>, and <envar>CLM_USRDAT_NAME</envar>.
<simplelist>
<member><emphasis><envar>PTS_MODE</envar></emphasis> -- to run for a single point
using global datasets</member>
<member><emphasis><envar>CLM_1PT_NAME</envar></emphasis> -- to run for a supported single-point
or regional dataset.</member>
<member><emphasis><envar>CLM_USRDAT_NAME</envar></emphasis> -- to run using your own datasets.</member>
</simplelist>
</para>

<sect1 id="PTS_MODE">
<title>Running PTS_MODE configurations</title>
<para>
<envar>PTS_MODE</envar> enables you to run the model using global datasets, but just picking a
single point from those datasets and operating on it. It can be a very quick way to do fast
simulations and get a quick turnaround.
</para>
<para>
To setup a <envar>PTS_MODE</envar> simulation you use the "-pts_lat" and "-pts_lon"
arguments to create_newcase to give the latitude and longitude of the point you want to
simulate for (the code will pick the point on the global grid nearest to the point you
give. Here's an example to setup a simulation for the nearest point at 2-degree resolution
to Boulder Colorado.
<screen>
> cd scripts
> create_newcase -case testPTS_MODE -res f19_g16 -compset I -mach bluefire -skip_rundb -pts_lat 40.0 -pts_lon -105
</screen>
Then configure, build and run as normal.
</para>
<note>
<para>
By default it sets up to run with
<envar>USE_MPISERIAL</envar> (in the <filename>env_builld.xml</filename> file) turned on, 
which allows you to run the model interactively. On some machines this mode is NOT 
supported and you may need to change it to FALSE before you are able to build.
</para>
</note>
<note>
<para>
<envar>PTS_MODE</envar> currently does <emphasis>NOT</emphasis> restart nor
is it able to startup from global initial condition files.
</para>
</note>
<note>
<para>
You can change the point you are simulating for at run-time by changing the values of
<envar>PTS_LAT</envar> and <envar>PTS_LON</envar> in the <filename>env_run.xml</filename> file.
</para>
</note>
</sect1>

<sect1 id="suprted_single_point_datasets">
<title>Running Supported Single-point Datasets</title>
<para>
In addition to <envar>PTS_MODE</envar> the CLM supports running using single-point or
regional datasets that are customized to a particular region. In the section below we
tell the user how to create their own dataset, but we also support a small number of
single-point and regional datasets that are ready to setup and run in the CCSM modeling
system.
</para>
<para>
To run with the supported single-point and regional datasets, you setup a simulation for the
"pt1_pt1" resolution and give the short-name for the file to use in the
<filename>env_conf.xml</filename> file. Then to run for the urban MexicoCity Mexico test site
do the following:
<screen>
> cd scripts
> create_newcase -case testSPDATASET -res pt1_pt1 -compset I -mach bluefire -skip_rundb
> cd testSPDATASET
> xmlchange -file env_conf.xml -id CLM_PT1_NAME -val 1x1_mexicocityMEX
</screen>
Then configure, build and run normally.
</para>
<note>
<para>
Just like <envar>PTS_MODE</envar> above, By default it sets up to run with
<envar>USE_MPISERIAL</envar> (in the <filename>env_builld.xml</filename> file) turned on, 
which allows you to run the model interactively. On some machines this mode is NOT 
supported and you may need to change it to FALSE before you are able to build.
</para>
</note>
</sect1>

<sect1 id="own_single_point_datasets">
<title>Creating your own single-point datasets</title>
<para>
The file:
<ulink url="../Quickstart.userdatasets">Quickstart.userdatasets</ulink> in the
<filename>models/lnd/clm/doc</filename> directory gives guidelines on how to create and run
with your own single-point or regional datasets.
</para>
</sect1>

</chapter>
<!-- End of single_point chapter -->


</book>
